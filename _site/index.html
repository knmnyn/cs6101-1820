<!DOCTYPE html>
<html dir="ltr" lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>CS6101 - Deep Reinforcement Learning</title>
	<meta name="keywords" content="CS6101, Deep Learning, Reinforcement Learning, RL, Games, Deep RL, Deep Reinforcement Learning, NUS">
	<meta name="description" content="This is a section of the CS 6101 Exploration of Computer Science Research at NUS. CS 6101 is a 4 modular credit pass/fail module for new incoming graduate programme students to obtain background in an area with an instructor's support. It is designed as a lab rotation to familiarize students with the methods and ways of research in a particular research area.  This semester's them will be on Deep Reinforcement Learning">
  <link rel="stylesheet" href="combo.css">
  <link href='http://fonts.googleapis.com/css?family=Raleway:400,300,700' rel='stylesheet' type='text/css'>
  <link rel="stylesheet" href="//netdna.bootstrapcdn.com/font-awesome/4.2.0/css/font-awesome.min.css">
  <link rel="shortcut icon" href="img/favicon.ico" type="image/x-icon">
	<link rel="apple-touch-icon" href="img/apple-touch-icon.png">
</head>
<body>
  <div id="main">

    <nav><ul>
      
        
        <li class="p-intro"><a href="#intro">CS6101 – Deep Reinforcement Learning</a></li>
      
        
        <li class="p-details"><a href="#details">Details</a></li>
      
        
        <li class="p-schedule"><a href="#schedule">Schedule</a></li>
      
        
        <li class="p-projects"><a href="#projects">Projects</a></li>
      
        
        <li class="p-links"><a href="#links">Other Links</a></li>
      
    </ul></nav>


    
      
      <div id="intro" class="section p-intro">
        
        <div class="container ">
          <div>
<img title="Photo by Samuel Zeller on Unsplash" alt="Photo by Samuel Zeller on Unsplash" src="img/samuel-zeller-90479-unsplash.jpg" class="img-fluid" style="float:left" height="150" /><p style="text-align:center; float:right"><h1>Deep Reinforcement Learning</h1><p style="text-align:center">NUS SoC, <b>2018/2019</b>, Semester II<br />CS 6101 - Exploration of Computer Science Research, Thu 15:00-17:00 @ MR6 (AS6 #05-10)</p></p>
</div>

<p><br clear="both" />
This course is taken almost verbatim from <a href="http://rail.eecs.berkeley.edu/deeprlcourse/">CS 294-112 Deep Reinforcement Learning</a> – <a href="https://people.eecs.berkeley.edu/~svlevine/">Sergey Levine</a>’s course at UC Berkeley. We are following his course’s formulation and selection of papers, with the permission of Levine.</p>

<p>This is a section of the CS 6101 Exploration of Computer Science Research at NUS. CS 6101 is a 4 modular credit pass/fail module for new incoming graduate programme students to obtain background in an area with an instructor’s support. It is designed as a “lab rotation” to familiarize students with the methods and ways of research in a particular research area.</p>

<p>Our section will be conducted as a group seminar, with class participants nominating themselves and presenting the materials and leading the discussion. It is not a lecture-oriented course and not as in-depth as Levine’s original course at UC Berkeley, and hence is not a replacement, but rather a class to spur local interest in Deep Reinforcement Learning.</p>

<p>This course is offered in Session I (Weeks 3-7) and Session II (Weeks 8-13), although it is clear that the course is logically a single course that builds on the first half.  Nevertheless, the material should be introductory and should be understandable given some prior study.</p>

<p><i class="fa fa-comments"></i>
<a href="http://cs6101.slack.com/">A mandatory discussion group is on Slack</a>. Students and guests, please login when you are free. If you have a @comp.nus.edu.sg, @u.nus.edu, @nus.edu.sg, @a-star.edu.sg, @dsi.a-star.edu.sg or @i2r.a-star.edu.sg. email address you can create your Slack account for the group discussion without needing an invite.</p>

<p><i class="fa fa-edit"></i>
<strong>For interested public participants</strong>, please send Min an email at <code>kanmy@comp.nus.edu.sg</code> if you need an invite to the Slack group.  The Slack group is being reused from previous semesters.  Once you are in the Slack group, you can consider yourself registered for the course.</p>


        </div>
      </div>
    
      
      <div id="details" class="section p-details">
        
        <div class="subtlecircle sectiondivider faicon">
          <span class="fa-stack">
            <i class="fa fa-circle fa-stack-2x"></i>
            <i class="fa fa-check-square-o fa-stack-1x"></i>
          </span>
          <h5 class="icon-title">Details</h5>
        </div>
        
        <div class="container ">
          <h2>Registration FAQ</h2>

<ul>
  <li>
    <p><strong>What are the pre-requisites?</strong></p>

    <p><em>From the original course</em>: Machine Learning or equivalent is a prerequisite for the course. This course will assume some familiarity with reinforcement learning, numerical optimization, and machine learning. For introductory material on RL and MDPs, see the CS188 EdX course, starting with Markov Decision Processes I, as well as Chapters 3 and 4 of Sutton &amp; Barto.</p>

    <p><em>For our NUS course iteration</em>, <font style="color:red">we believe you should also follow the above pre-requisites, where possible.</font> <s>there are no formal prerequisites for the course.</s>  As with many machine learning courses, it would be useful to have basic understanding of linear algebra, machine learning, and probability and statistics.  Taking online, open courses on these subjects concurrently or before the course is definitely advisable, if you do not have to requisite understanding.  You might try to follow the preflight video lectures, and if these are understandable to you, then you’re all good.</p>
  </li>
  <li>
    <p><strong>Is the course chargeable?</strong> <strong>No,</strong> the course is not chargeable.  It is free (as in no-fee).  NUS allows us to teach this course for free, as it is not “taught”, <em>per se</em>.  Students in the class take charge of the lectures, and complete a project, while the teaching staff facilitates the experience.</p>
  </li>
  <li>
    <p><strong>Can I get course credit for taking this?</strong> <strong>Yes,</strong> if you are a first-year School of Computing doctoral student.  In this case you need to formally enroll in the course as CS6101, And you will receive one half of the 4-MC pass/fail credit that you would receive for the course, which is a lab rotation course.  Even though the left rotation is only for half the semester, such students are encouraged and welcome to complete the entire course.</p>

    <p><strong>No,</strong>  for everyone else.  By this we mean that no credits, certificate, or any other formal documentation for completing the course will be given to any other participants, inclusive of external registrants and NUS students (both internal and external to the School of Computing).  Such participants get the experience of learning deep learning together in a formal study group in developing the camaraderie and network from fellow peer students and the teaching staff.</p>
  </li>
  <li><strong>What are the requirements for completing the course?</strong> Each student must achieve 2 objectives  to be deemed to have completed the course:
    <ul>
      <li>Work with peers to assist in teaching two lecture sessions of the course: One lecture by co-lecturing the subject from new slides that you have prepared a team; and another lecture as a scribe: moderating the Slack channel to add materials for discussion and taking public class notes.  All lecture materials by co-lecturers and scribes will be made public.</li>
      <li>Complete a deep reinforcement learning project. For the project, you only need to use any deep learning framework to execute a problem against a data set.  You may choose to replicate previous work from others in scientific papers or data science challenges. Or more challengingly, you may decide to use data from your own context.</li>
    </ul>
  </li>
  <li>
    <p><strong>How do external participants take this course?</strong> You may come to
  NUS to participate in the lecture concurrently with all of our
  local participants.  You are also welcome to participate online
  through Google Hangouts.  We typically have a synchronous
  broadcast to Google Hangouts that is streamed and archived to
  YouTube.</p>

    <p>During the session where you’re responsible for co-lecturing, you
  will be expected to come to the class in person.</p>

    <p>As an external participant, you <strong>are</strong> obligated to complete the
  course to best your ability.  We do not encourage students who are
  not committed to completing the course to enrol.</p>
  </li>
</ul>

<h2>Meeting Venue and Time</h2>

<p>For both Sessions (I and II): 15:00-17:00, Thursdays at Meeting Room 6 (AS6 #05-10)</p>

<p>For directions to NUS School of Computing (SoC) and COM1: please read <a href="http://www.comp.nus.edu.sg/maps/getting-here/">the directions here</a>, to park in CP13 and/or take the bus to SoC. and use <a href="http://www.comp.nus.edu.sg/images/resources/content/mapsvenues/AS6_L5.jpg">the floorplan</a></p>

<h2>People</h2>

<p>Welcome. If you are an external visitor and would like to join us, please email Kan Min-Yen to be added to the class role. Guests from industry, schools and other far-reaching places in SG welcome, pending space and time logistic limitations. The more, the merrier.</p>

<p>External guests will be listed here in due course once the course has started. Please refer to our Slack after you have been invited for the most up-to-date information.</p>

<p><strong>NUS (Postgraduate)</strong>: Session I (Weeks 3-7): Yong Liang Goh, Yihui Chong, Qian Lin, Yu Ning, Saravanan Rajamanickam, Ying Kiat Tan</p>

<p><strong>NUS (Postgraduate)</strong>: Session II (Weeks 8-13):</p>

<p><strong>NUS (Undergraduate, Cross-Faculty and Alumni)</strong>: Daniel Biro, Joel Lee, Yong Ler Lee</p>

<p><strong><a href="http://wing.comp.nus.edu.sg">WING</a></strong>: Kishaloy Halder, 
<a href="http://www.comp.nus.edu.sg/~kanmy/">Min-Yen Kan</a>, Jethro Kuan, Liangming Pan, Chenglei Si, Weixin Wang,</p>

<p><strong>Guests</strong>: Shen Ting Ang, Takanori Aoki, Vicky Feliren, Theodore Galanos, Alexandre Gravier, Markus Kirchberg, Joash Lee, Joo Gek Lim, Wuqiong Luo (Nick), Xiao Nan, Shi Kang Ng, Vikash Ranjan, Praveen Sanap, Kok Keong Teo</p>

        </div>
      </div>
    
      
      <div id="schedule" class="section p-schedule">
        
        <div class="subtlecircle sectiondivider faicon">
          <span class="fa-stack">
            <i class="fa fa-circle fa-stack-2x"></i>
            <i class="fa fa-calendar fa-stack-1x"></i>
          </span>
          <h5 class="icon-title">Schedule</h5>
        </div>
        
        <div class="container ">
          <style type="text/css">
  td { padding:5px; }
</style>

<h2>Schedule</h2>

<p>Don’t limit yourself to the materials provided by Levine when preparing.  There are also other good resources such as those prepared by <a href="http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html">Silver</a> on traditional RL.  We’ll try to post links and synchronize where possible.</p>

<table class="table table-striped">
<thead class="thead-inverse"><tr><th>Date</th><th width="60%">Description</th><th>Deadlines</th></tr></thead>
<tbody>
<tr>
  <td><b>Preflight</b><br />Week of 17, 24 Jan
  </td>
  <td>
  <strong>
  Introduction and Course Overview
  </strong>
  [<a href="https://www.youtube.com/watch?v=opaBjK4TfLc">Video&nbsp;(@UCB)</a>,
  <a href="http://rail.eecs.berkeley.edu/deeprlcourse/static/slides/lec-1.pdf">Slides (@UCB)</a>]
  <br />
  <strong>
  Supervised Learning and Imitation
  </strong>
  [<a href="https://www.youtube.com/watch?v=yPMkX_6-ESE">Video&nbsp;(@UCB)</a>,
  <a href="http://rail.eecs.berkeley.edu/deeprlcourse/static/slides/lec-2.pdf">Slides (@UCB)</a>]
  , &amp;
  <br />
  <strong>
  TensorFlow and Neural Nets Review Session (notebook)
  </strong>
  [<a href="https://www.youtube.com/watch?v=xZKj7Z1CwHc">Video&nbsp;(@UCB)</a>,
  <a href="http://rail.eecs.berkeley.edu/deeprlcourse/static/slides/lec-3.pdf">Slides (@UCB)</a>]
  </td>
  <td>
  </td>
</tr>
<tr>
  <td><b>Week 3</b><br />31 Jan
  </td>
  <td><strong>
  Reinforcement Learning Introduction
  </strong>
  [<a href="https://www.youtube.com/watch?v=ml8wUkE0M6U">Video&nbsp;(@UCB)</a>,
  <a href="http://rail.eecs.berkeley.edu/deeprlcourse/static/slides/lec-4.pdf">Slides (@UCB)</a>]
  ,
  <br />
  <strong>
  Policy Gradients Introduction
  </strong>
  [<a href="https://www.youtube.com/watch?v=XGmd3wcyDg8">Video&nbsp;(@UCB)</a>,
  <a href="http://rail.eecs.berkeley.edu/deeprlcourse/static/slides/lec-5.pdf">Slides (@UCB)</a>]
  , &amp;
  <br />
  [&nbsp;»&nbsp;<a href="w03.pdf">Scribe&nbsp;Notes</a>&nbsp;]
  [&nbsp;»&nbsp;<a href="#" data-toggle="#div3">Recording&nbsp;@&nbsp;YouTube&nbsp;</a>&nbsp;]
<div id="div3" style="display:none">
  <iframe width="700" height="500" src="https://www.youtube.com/embed/jf70iPc_F8s" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</div>
  </td>
  <td>
  </td>
</tr>
<tr>
  <td><b>Week 4</b><br />7 Feb
  </td>
  <td>
  <strong>
  Actor-Critic Introduction
  </strong>
  [<a href="https://www.youtube.com/watch?v=Tol_jw5hWnI">Video&nbsp;(@UCB)</a>,
  <a href="http://rail.eecs.berkeley.edu/deeprlcourse/static/slides/lec-6.pdf">Slides (@UCB)</a>]
<br />
  <strong>
  Value Functions and Q-Learning
  </strong>
  [<a href="https://www.youtube.com/watch?v=chLN1e3ehZE">Video&nbsp;(@UCB)</a>,
  <a href="http://rail.eecs.berkeley.edu/deeprlcourse/static/slides/lec-7.pdf">Slides (@UCB)</a>]
  , &amp;
  <br />
  [&nbsp;»&nbsp;<a href="w04.pdf">Scribe&nbsp;Notes</a>&nbsp;]
  [&nbsp;»&nbsp;<a href="#" data-toggle="#div4">Recording&nbsp;@&nbsp;YouTube&nbsp;</a>&nbsp;]
<div id="div4" style="display:none">
  <iframe width="700" height="500" src="https://www.youtube.com/embed/wzBu8AzNrSY" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</div>
</td>
  <td>
</td>
</tr>
<tr>
  <td><b>Week 5</b><br />14 Feb
  </td>
  <td>
  <strong>
  Advanced Q-Learning Algorithms
  </strong>
  [<a href="https://www.youtube.com/watch?v=hP1UHU_1xEQ">Video&nbsp;(@UCB)</a>,
  <a href="http://rail.eecs.berkeley.edu/deeprlcourse/static/slides/lec-8.pdf">Slides (@UCB)</a>]
<br />
[&nbsp;»&nbsp;<a href="#" data-toggle="#div5">Recording&nbsp;@&nbsp;YouTube&nbsp;</a>&nbsp;]
<div id="div5" style="display:none">
<iframe width="700" height="500" src="https://www.youtube.com/embed/cAD5B4AV2e4?start=350" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</div>
  </td>
  <td>
  </td>
</tr>
<tr>
  <td><b>Week 6</b><br />21 Feb
  </td>
  <td>
<strong>
  Advanced Policy Gradients
  </strong>
  [<a href="https://www.youtube.com/watch?v=6v4syGD--hQ">Video&nbsp;(@UCB)</a>,
  <a href="http://rail.eecs.berkeley.edu/deeprlcourse/static/slides/lec-9.pdf">Slides (@UCB)</a>]
<br />
</td>
  <td>Preliminary project titles and team members due on Slack's <code>#projects</code>
  </td>
</tr>
<tr>
  <td><b>Recess Week</b><br />28 Feb
  </td>
  <td>
  <strong>
  Optimal Control and Planning
  </strong>
  [<a href="https://www.youtube.com/watch?v=8-cEIknXtaI">Video&nbsp;(@UCB)</a>,
  <a href="http://rail.eecs.berkeley.edu/deeprlcourse/static/slides/lec-10.pdf">Slides (@UCB)</a>]
<br />
</td>
  <td>
  </td>
</tr>
<tr>
  <td><b>Week 7</b><br />7 Mar
  </td>
  <td>
  <strong>
  Model-Based Reinforcement Learning
  </strong>
  [<a href="https://www.youtube.com/watch?v=os3sIwVHfCk">Video&nbsp;(@UCB)</a>,
  <a href="http://rail.eecs.berkeley.edu/deeprlcourse/static/slides/lec-11.pdf">Slides (@UCB)</a>]
<br />
  <strong>
  Advanced Model Learning and Images
  </strong>
  [<a href="https://www.youtube.com/watch?v=eF5Ka834TCA">Video&nbsp;(@UCB)</a>,
  <a href="http://rail.eecs.berkeley.edu/deeprlcourse/static/slides/lec-12.pdf">Slides (@UCB)</a>]
<br />
</td>
  <td>Preliminary abstracts due to <code>#projects</code>
  </td>
</tr>
<tr>
  <td><b>Week 8</b><br />14 Mar
  </td>
  <td>
  <strong>
  Learning Policies by Imitating Other Policies
  </strong>
  [<a href="https://www.youtube.com/watch?v=xbQQ1xkYDug">Video&nbsp;(@UCB)</a>,
  <a href="http://rail.eecs.berkeley.edu/deeprlcourse/static/slides/lec-13.pdf">Slides (@UCB)</a>]
<br />
  </td>
  <td>
  </td>
</tr>
<tr>
  <td><b>Week 9</b><br />21 Mar
  </td>
  <td>
  <strong>
  Probability and Variational Inference Primer
  </strong>
  [<a href="https://www.youtube.com/watch?v=1bpQ0QDPGuI">Video&nbsp;(@UCB)</a>,
  <a href="http://rail.eecs.berkeley.edu/deeprlcourse/static/slides/lec-14.pdf">Slides (@UCB)</a>]
<br />
  <strong>
  Connection between Inference and Control
  </strong>
  [<a href="https://www.youtube.com/watch?v=oqvTC1rTjg8">Video&nbsp;(@UCB)</a>,
  <a href="http://rail.eecs.berkeley.edu/deeprlcourse/static/slides/lec-15.pdf">Slides (@UCB)</a>]
  <br />
  </td>
  <td>
  </td>
</tr>
<tr>
  <td><b>Week 10</b><br />28 Mar
  </td>
  <td>
    <strong>
  Inverse Reinforcement Learning
  </strong>
  [<a href="https://www.youtube.com/watch?v=YnistinWUv4">Video&nbsp;(@UCB)</a>,
  <a href="http://rail.eecs.berkeley.edu/deeprlcourse/static/slides/lec-16.pdf">Slides (@UCB)</a>]
<br />
</td>
  <td>
  </td>
</tr>
<tr>
  <td><b>Week 11</b><br />4 Apr
  </td>
  <td>(warning: we skip a few lectures to get here)<br />
<strong>
  Exploration: Part 1
  </strong>
  [<a href="https://www.youtube.com/watch?v=krNJGBcEEzU">Video&nbsp;(@UCB)</a>,
  <a href="http://rail.eecs.berkeley.edu/deeprlcourse/static/slides/lec-17.pdf">Slides (@UCB)</a>]
  , &amp;
  <br />
  <strong>
  Exploration: Part 2
  </strong>
  [<a href="https://www.youtube.com/watch?v=yRAphPPbBYI">Video&nbsp;(@UCB)</a>,
  <a href="http://rail.eecs.berkeley.edu/deeprlcourse/static/slides/lec-18.pdf">Slides (@UCB)</a>]
  <br />
</td>
  <td>
  </td>
</tr>
<tr>
  <td><b>Week 12</b><br />11 Apr
  </td>
  <td>
  <strong>
  Parallelism and RL System Design
  </strong>
  [<a href="https://www.youtube.com/watch?v=Y6feXBY6_XQ">Video&nbsp;(@UCB)</a>,
  <a href="http://rail.eecs.berkeley.edu/deeprlcourse/static/slides/lec-21.pdf">Slides (@UCB)</a>]
  <br />
  </td>
  <td>
  </td>
</tr>
<tr>
  <td><b>Week 13</b><br />18 Apr
  </td>
  <td>
  <strong>
  Advanced Imitation Learning and Open Problems
  </strong>
  [<a href="https://www.youtube.com/watch?v=RE_4L7SoatA">Video&nbsp;(@UCB)</a>,
  <s>Slides</s>] 
<br />
  </td>
  <td>Participation on evening of 14th STePS
  </td>
</tr>
</tbody></table>


        </div>
      </div>
    
      
      <div id="projects" class="section p-projects">
        
        <div class="subtlecircle sectiondivider faicon">
          <span class="fa-stack">
            <i class="fa fa-circle fa-stack-2x"></i>
            <i class="fa fa-bar-chart fa-stack-1x"></i>
          </span>
          <h5 class="icon-title">Projects</h5>
        </div>
        
        <div class="container ">
          <h2>Student Projects</h2>

<p><em>Coming soon!</em></p>

        </div>
      </div>
    
      
      <div id="links" class="section p-links">
        
        <div class="subtlecircle sectiondivider faicon">
          <span class="fa-stack">
            <i class="fa fa-circle fa-stack-2x"></i>
            <i class="fa fa-plug fa-stack-1x"></i>
          </span>
          <h5 class="icon-title">Other Links</h5>
        </div>
        
        <div class="container ">
          <p>If you are already registered for the course, please find (and post) resources to the #general Slack channel.</p>

<ul>
  <li>UCB’s Subreddit <strong>r/berkeleydeeprlcourse</strong> - <a href="https://www.reddit.com/r/berkeleydeeprlcourse/">https://www.reddit.com/r/berkeleydeeprlcourse/</a></li>
</ul>

<p>RL Textbooks and Lectures:</p>

<ul>
  <li><strong>Sutton and Barto, <em>Reinforcement Learning: An Introduction</em></strong> - free e-book on general RL inclusive of Deep RL.  Becoming a standard text. <a href="http://incompleteideas.net/book/the-book-2nd.html">http://incompleteideas.net/book/the-book-2nd.html</a></li>
  <li><strong>Szepesvari, <em>Algorithms for Reinforcement Learning</em></strong> - <a href="https://sites.ualberta.ca/~szepesva/RLBook.html">https://sites.ualberta.ca/~szepesva/RLBook.html</a></li>
  <li>**David Silver’s lectures (some on YouTube): <a href="http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html">http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html</a>. Some have expressed that this is easier to start with.</li>
  <li><strong>(Easier) CS 188, UC Berkeley</strong>.  Two introduction lectures on Reinforcement Learning (scroll down to Week 5), video links included - <a href="http://inst.eecs.berkeley.edu/~cs188/fa18/">http://inst.eecs.berkeley.edu/~cs188/fa18/</a></li>
  <li>For others, please see the original list from Levine:</li>
</ul>

<p>General Texts:</p>

<ul>
  <li><strong>Ian Goodfellow, Yoshua Bengio and Aaron Courville <em>Deep Learning</em></strong> - an MIT Press book <a href="http://www.deeplearningbook.org/">http://www.deeplearningbook.org/</a></li>
  <li><strong>Michael A. Nielsen, <em>Neural Networks and Deep Learning</em></strong> - free, general e-book - <a href="http://neuralnetworksanddeeplearning.com/">http://neuralnetworksanddeeplearning.com/</a></li>
</ul>

<p>RL computing resources / frameworks:</p>

<ul>
  <li><strong>Open AI Gym</strong> - <a href="https://gym.openai.com/">https://gym.openai.com/</a></li>
  <li><strong>Google Dopamine</strong> - <a href="https://github.com/google/dopamine/">https://github.com/google/dopamine/</a></li>
</ul>

<p>Previous CS6101 versions run by Min:</p>

<ul>
  <li><strong>Deep Learning for NLP</strong> (reprise) - <a href="http://www.comp.nus.edu.sg/~kanmy/courses/6101_1810/">http://www.comp.nus.edu.sg/~kanmy/courses/6101_1810</a></li>
  <li><strong>Deep Learning via Fast.AI</strong> - <a href="http://www.comp.nus.edu.sg/~kanmy/courses/6101_2017_2/">http://www.comp.nus.edu.sg/~kanmy/courses/6101_2017_2/</a></li>
  <li><strong>Deep Learning for Vision</strong> - <a href="http://www.comp.nus.edu.sg/~kanmy/courses/6101_2017/">http://www.comp.nus.edu.sg/~kanmy/courses/6101_2017/</a></li>
  <li><strong>Deep Learning for NLP</strong> - <a href="http://www.comp.nus.edu.sg/~kanmy/courses/6101_2016_2/">http://www.comp.nus.edu.sg/~kanmy/courses/6101_2016_2/</a></li>
  <li><strong>MOOC Research</strong> - <a href="http://www.comp.nus.edu.sg/~kanmy/courses/6101_2016/">http://www.comp.nus.edu.sg/~kanmy/courses/6101_2016/</a></li>
</ul>

        </div>
      </div>
    


    <div id="footer" class="section text-white">
      <div class="container">
        
        <p>Design forked from 
<a href="https://github.com/t413/SinglePaged">SinglePaged theme</a>
by Tim O’Brien <a href="http://t413.com/">t413.com</a></p>


      </div>
    </div>
  </div>


<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-9594235-3']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>

</body>
<script src="//ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js"></script>
<script src="site.js"></script>
</html>
